{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - Machine Learning from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer,OneHotEncoder,LabelEncoder,StandardScaler\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      "Country      10 non-null object\n",
      "Age          9 non-null float64\n",
      "Salary       9 non-null float64\n",
      "Purchased    10 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 400.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/omkarmutreja/Downloads/Data_Preprocessing/Data.csv')\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data - Replacing by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,3].values\n",
    "# print(\"X: \",X)\n",
    "# print(\"y: \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values='NaN',strategy='mean',axis=0)\n",
    "imputer = imputer.fit(X[:,1:3])\n",
    "X[:,1:3] = imputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Data - Creating Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [1. 0. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "\n",
      "y: [0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "labelencoder_X = LabelEncoder() \n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "print(\"X: \", X[:,0])\n",
    "print(\"\")\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X set:  (8, 11)\n",
      "Training y  set:  (8,)\n",
      "\n",
      "Testing X set:  (2, 11)\n",
      "Testing y  set:  (2,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=0 )\n",
    "print(\"Training X set: \",X_train.shape)\n",
    "print(\"Training y  set: \",y_train.shape)\n",
    "print(\"\")\n",
    "print(\"Testing X set: \",X_test.shape)\n",
    "print(\"Testing y  set: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two types of Feature Scaling:\n",
    "### 1. Standardization : x-mean(x) / StD(x)\n",
    "### 2. Normalisation : x-min(x) / max(x)-min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Scaling the dummy variables depends on the context\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "# All values are scaled between -1 and +1\n",
    "# Helps our machine learning model to work faster with greater accuracy\n",
    "print(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
